{
 "metadata": {
  "name": "",
  "signature": "sha256:968d3fa01306470cbadef90d3f1ceba1b4713faa18085a739b8c712b0a225a09"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CLEAN deconvolution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we create a simple example of the CLEAN deconvolution algorithm, using 1D visibilities and \"images\".\n",
      "\n",
      "First import the necessary modules:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "%matplotlib inline\n",
      "import copy\n",
      "from scipy.optimize import curve_fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make our convenience functions using the fourier transform provided by numpy (don't worry about the details of this now!):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def ft(y):\n",
      "    \"\"\"Returns the fourier transform of y\"\"\"\n",
      "    return np.fft.fftshift(np.fft.fft(np.fft.fftshift(y)))\n",
      "\n",
      "def ftfreqs(N,dt):\n",
      "    \"\"\"Returns the Fourier frequencies\"\"\"\n",
      "    return np.fft.fftshift(np.fft.fftfreq(N,dt))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets define some functions for use later:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# top-hat function\n",
      "def tophat(t,width,A):\n",
      "    output = np.zeros(len(t))\n",
      "    output[abs(t)<width/2.0] = A\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we create the visibilities for a 1D sky with three point sources in it.\n",
      "\n",
      "First start off by setting up our $u$ and $l$ variables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "delta_u = 0.5\n",
      "u = np.arange(-3000,3000,delta_u)          # visibility plane variable u\n",
      "l = ftfreqs(len(u),delta_u)                # image plane variable l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We calculate the visibilities for each point source, add them, then Fourier Transform the visibilities V($u$) to get our ideal sky image I($l$).\n",
      "\n",
      "We are going to create sources at positions $l$=0.7, 0.64 and -0.2. You can change these later!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "V1 = 5.0*(1./len(u))*np.exp(1.0j*2.*np.pi*u*0.7)        # point source 1\n",
      "V2 = 2.0*(1./len(u))*np.exp(1.0j*2.*np.pi*u*-0.2)       # point source 2\n",
      "V3 = 0.4*(1./len(u))*np.exp(1.0j*2.*np.pi*u*0.64)       # point source 3\n",
      "V = V1+V2+V3                                            # sum them to get total visibility\n",
      "I = ft(V)                                               # Fourier transform visibility to get ideal sky image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the visibilities and the sky image (amplitude, real and imaginary):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitudes\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3]);     \n",
      "ax[0].plot(u,np.abs(V));\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('V($u$) (Amplitude)');\n",
      "ax[0].set_xlim(-50.,50.);\n",
      "ax[1].plot(l,np.abs(I));\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('I($l$) (Amplitude)');\n",
      "\n",
      "# plot real values\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3]); \n",
      "ax[0].plot(u,V.real);\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('V($u$) (Real)');\n",
      "ax[0].set_xlim(-50.,50.);\n",
      "ax[1].plot(l,I.real);\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('I($l$) (Real)');\n",
      "\n",
      "# plot imaginary values\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3]); \n",
      "ax[0].plot(u,V.imag);\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('V($u$) (Imag)');\n",
      "ax[0].set_xlim(-50.,50.);\n",
      "ax[1].plot(l,I.imag);\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('I($l$) (Imag)');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets \"sample\" our visibilities and see how sampling the visibilities amounts to convolving our image by a PSF (or dirty beam).\n",
      "\n",
      "Remember the convolution theorem:\n",
      "\n",
      "$$ f . g \\Leftrightarrow F * G$$\n",
      "\n",
      "In our case, we are multiplying our visibility V by a sampling function S.\n",
      "The fourier transform of the visibility V is the ideal image I, $V \\Leftrightarrow I$.\n",
      "The fourier transform of the sampling function S is the point spread function PSF (also called the synthesized beam),\n",
      "$S \\Leftrightarrow PSF$.\n",
      "\n",
      "So we have:\n",
      "\n",
      "$$ V . S \\Leftrightarrow I * PSF $$\n",
      "\n",
      "The ideal image convolved with the PSF is called the dirty image, DI.\n",
      "\n",
      "In a real interferometer, the sampling function S comes from the baseline tracks in the $u$-$v$ plane. Here we are just going to use a top hat function to represent a simple sampling function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = tophat(u,80.,1.)\n",
      "# normalise the sampling function by power\n",
      "normalisation_factor = len(S)/sum(S)\n",
      "S = S*normalisation_factor\n",
      "\n",
      "PSF = ft(S)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We used a relatively wide samping function here, with a total width of 80. This will give us a relatively narrow PSF. Try running this notebook again later using a narrower sampling function (for example, with a total width of 20). You will see a wider PSF. In a real inteferometer this would correspond to a shorter baseline array, with lower resolution. \n",
      "\n",
      "Now plot our sampling function and PSF, in amplitude, real and imaginary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitude\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3])     \n",
      "ax[0].plot(u,np.abs(S))\n",
      "ax[0].set_xlabel('$u$')\n",
      "ax[0].set_ylabel('S($u$)) (Amplitude)')\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,np.abs(PSF))\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('PSF($l$) (Amplitude)')\n",
      "ax[1].set_xlim(-0.15,0.15);\n",
      "\n",
      "# plot real\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3])     \n",
      "ax[0].plot(u,S.real)\n",
      "ax[0].set_xlabel('$u$')\n",
      "ax[0].set_ylabel('S($u$)) (Real)')\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,PSF.real)\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('PSF($l$) (Real)')\n",
      "ax[1].set_xlim(-0.15,0.15);\n",
      "\n",
      "# plot imag\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3])     \n",
      "ax[0].plot(u,S.imag)\n",
      "ax[0].set_xlabel('$u$')\n",
      "ax[0].set_ylabel('S($u$)) (Imag)')\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,PSF.imag)\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('PSF($l$) (Imag)')\n",
      "ax[1].set_xlim(-0.15,0.15);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets multiply our visibilities V by the sampling function S. We will see how this amounts to a convolution of the ideal image I by the PSF in the image plane, to give the dirty image DI."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sampled_V = V*S \n",
      "DI = ft(sampled_V)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now plot our sampled visibiliby and the dirty image DI, in amplitude, real and imaginary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitude\n",
      "fig, ax = plt.subplots(1,2,figsize=[16,3]);    \n",
      "ax[0].plot(u,np.abs(sampled_V));\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('Sampled V($u$)) (Amplitude)');\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,np.abs(DI));\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('DI($l$) (Amplitude)');\n",
      "\n",
      "# plot real\n",
      "fig, ax = plt.subplots(1,2,figsize=[16,3]);   \n",
      "ax[0].plot(u,sampled_V.real);\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('Sampled V($u$)) (Real)');\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,DI.real);\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('DI($l$) (Real)');\n",
      "\n",
      "# plot imag\n",
      "fig, ax = plt.subplots(1,2,figsize=[16,3]);     \n",
      "ax[0].plot(u,sampled_V.imag);\n",
      "ax[0].set_xlabel('$u$');\n",
      "ax[0].set_ylabel('Sampled V($u$)) (Imag)');\n",
      "ax[0].set_xlim(-250.,250.);\n",
      "ax[1].plot(l,DI.imag);\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('DI($l$) (Imag)');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets try to Deconvolve our dirty image!\n",
      "\n",
      "A detail:\n",
      "We need to pad the PSF to double its extent (add zeros to the edges) for when we subtract it in the CLEAN algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##CLEAN##\n",
      "\n",
      "Now let's do the CLEAN deconvolution! \n",
      "\n",
      "Remember the CLEAN algorithm:\n",
      "\n",
      "####H\u00f6gbom's Algorithm (Image-domain CLEAN):####\n",
      "Inputs: Dirty Image, PSF\n",
      "<br>\n",
      "Parameters: gain, end threshold\n",
      "\n",
      "1. Make a copy of Dirty Image, call it the Residual Image\n",
      "   Create an empty Model\n",
      "2. while(End threshold not reached):\n",
      "   1. Find the pixel $p_{max}$  with the largest flux $f_{max}$ in the Residual Image\n",
      "   2. Subtract  gain*PSF centred on $p_{max}$ and update the Residual Image\n",
      "   3. In the Model, save the position $p_{max}$ and amplitude gain*$f_{max}$ of the subtracted component\n",
      "3. Convolve the Model with the 'restored' beam, and add it to the final Residual Image to produce the Restored Image\n",
      "\n",
      "Output: Model, Residual Image, Restored Image\n",
      "\n",
      "We are going to clean iteration by iteration, and watch how the residual image changes.\n",
      "\n",
      "A detail:\n",
      "We need to pad the PSF to double its extent (add zeros to the edges) for when we subtract it in the CLEAN algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gain = 0.2\n",
      "\n",
      "PSF_padded = np.pad(PSF,len(u)/2,mode='constant',constant_values=0)\n",
      "# normalise\n",
      "PSF_padded = PSF_padded/np.max(PSF_padded)\n",
      "PSF_padded_len = len(PSF_padded)\n",
      "\n",
      "# set up list to contain our clean components\n",
      "clean_component_list = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 1\n",
      "\n",
      "# this is just to make sure we are working on copies of the data, not modifying the originals\n",
      "PSF_padded = copy.deepcopy(PSF_padded)  \n",
      "resid_I = copy.deepcopy(DI)\n",
      "\n",
      "# this command finds the index in Y whereY is maximum\n",
      "maxindex = np.argmax(resid_I)\n",
      "maxI =  resid_I[maxindex]\n",
      "# print the the values of l and resid_I at the maximum index\n",
      "print 'Iter: {0}       l: {1}      I: {2}'.format(i,l[maxindex],np.abs(maxI))\n",
      "\n",
      "PSF_to_subtract = copy.deepcopy(PSF_padded[PSF_padded_len/2-maxindex:len(PSF)+(PSF_padded_len/2-maxindex)])\n",
      "PSF_to_subtract /= np.max(PSF_to_subtract)\n",
      "resid_I = resid_I - gain*maxI*PSF_to_subtract\n",
      "clean_component_list.append([maxindex,maxI])\n",
      "\n",
      "# plot \n",
      "fig, ax = plt.subplots(1,2,figsize=[16,4])  \n",
      "ax[0].plot(l,DI.real)\n",
      "ax[0].set_xlabel('$l$')\n",
      "ax[0].set_ylabel('DI($l$) (Real)')\n",
      "ax[1].plot(l,resid_I.real)\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('resid_I($l$) (Real)')\n",
      "\n",
      "ax[0].set_ylim(-1.,5.2);\n",
      "ax[1].set_ylim(-1.,5.2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now for the next iterations, shift-enter on the cell below multiple times to see how the CLEAN is happening.\n",
      "We want around 22+ iterations.\n",
      "\n",
      "For each iteration, we:\n",
      "* Print the details of the CLEAN component subtracted in that iteration\n",
      "* Plot the residual image at the end of the iteration\n",
      "\n",
      "Watch to see which of the sources each iteration is picking up (the $l$=0.7, 0.64 or -0.2 sources), and how the intensity in the residual image is decreasing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = i + 1\n",
      "\n",
      "# this is just to make sure we are working on copies of the data, not modifying the originals\n",
      "PSF_padded = copy.deepcopy(PSF_padded)  \n",
      "resid_I = copy.deepcopy(resid_I)\n",
      "\n",
      "# this command finds the index in Y whereY is maximum\n",
      "maxindex = np.argmax(resid_I)\n",
      "maxI =  resid_I[maxindex]\n",
      "# print the the values of l and resid_I at the maximum index\n",
      "print 'Iter: {0}       l: {1}      I: {2}'.format(i,l[maxindex],np.abs(maxI))\n",
      "\n",
      "PSF_to_subtract = copy.deepcopy(PSF_padded[PSF_padded_len/2-maxindex:len(PSF)+(PSF_padded_len/2-maxindex)])\n",
      "PSF_to_subtract /= np.max(PSF_to_subtract)\n",
      "resid_I = resid_I - gain*maxI*PSF_to_subtract\n",
      "clean_component_list.append([maxindex,maxI])\n",
      "\n",
      "# plot \n",
      "fig, ax = plt.subplots(1,2,figsize=[16,4])  \n",
      "ax[0].plot(l,DI.real)\n",
      "ax[0].set_xlabel('$l$'); ax[0].set_ylabel('DI($l$) (Real)')\n",
      "ax[1].plot(l,resid_I.real)\n",
      "ax[1].set_xlabel('$l$'); ax[1].set_ylabel('resid_I($l$) (Real)')\n",
      "\n",
      "ax[0].set_ylim(-1.,5.2); ax[1].set_ylim(-1.,5.2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you are happy with your CLEAN (~22+ iterations), lets plot our model sky build up out of our clean components:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_I = np.zeros(len(I))\n",
      "\n",
      "for index, amp in clean_component_list:\n",
      "    model_I[index] = model_I[index] + gain*amp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot our model next to the original:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitudes\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3])     \n",
      "ax[0].plot(l,np.abs(DI))\n",
      "ax[0].set_xlabel('$l$')\n",
      "ax[0].set_ylabel('DI($l$) (Amplitude)')\n",
      "ax[0].set_ylim(0,5);\n",
      "ax[1].plot(l,np.abs(model_I))\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('model I($l$) (Amplitude)')\n",
      "ax[1].set_ylim(0,5);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why does the $l$=0.7 model amplitude seem so much lower than the original amplitude? Let's zoom in on it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitudes\n",
      "fig, ax = plt.subplots(1,2,figsize=[13,3])     \n",
      "ax[0].plot(l,np.abs(DI),'o-')\n",
      "ax[0].set_xlabel('$l$')\n",
      "ax[0].set_ylabel('DI($l$) (Amplitude)')\n",
      "ax[0].set_ylim(0,5);\n",
      "ax[0].set_xlim(0.69,0.71);\n",
      "ax[1].plot(l,np.abs(model_I),'o-')\n",
      "ax[1].set_xlabel('$l$')\n",
      "ax[1].set_ylabel('model I($l$) (Amplitude)')\n",
      "ax[1].set_ylim(0,5);\n",
      "ax[1].set_xlim(0.69,0.71);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So our CLEAN algorithm modelled the $l$=0.7 sources as clean components in multiple adjactent pixels. Just from the plot above, we see that the components look like they will add up to an amplitude of 5."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now as a final step, we convolve our model by a \"restoring beam\" which is a Gaussian fit to the central lobe of the PSF (or synthesized beam), and add back our final residual image (the \"leftovers\" from our model) to get our final restored CLEAN image.\n",
      "\n",
      "First lets do the Gaussian fit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gaussian function\n",
      "def gaussian(t,sigma,C):\n",
      "    return C*(1./(np.sqrt(2.*np.pi)*sigma))*np.exp(-t**2.0/(2.0*sigma**2.0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the extent of the main lobe in the PSF\n",
      "positive_indices = np.where(PSF[len(PSF)/2:]>0)[0]\n",
      "offsets = np.array([positive_indices[j]-positive_indices[j-1] for j in range(1,len(positive_indices))])\n",
      "lobe_offset_index = np.where(offsets>1)[0][0]\n",
      "lobe_min_index = len(PSF)/2-lobe_offset_index\n",
      "lobe_max_index = len(PSF)/2+lobe_offset_index\n",
      "\n",
      "# extract just the main lobe to fit\n",
      "PSF_main_lobe = copy.deepcopy(PSF)\n",
      "PSF_main_lobe[0:lobe_min_index] = 0 \n",
      "PSF_main_lobe[lobe_max_index:] = 0 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now do a Gaussian fit to the PSF main lobe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "popt, pcov = curve_fit(gaussian, l, np.abs(PSF_main_lobe))\n",
      "\n",
      "sigma = popt[0]\n",
      "C = popt[1]\n",
      "fitted_beam = gaussian(l,sigma,C)\n",
      "# normalise the restoring beam\n",
      "restoring_beam = fitted_beam/np.max(fitted_beam)\n",
      "\n",
      "plt.plot(l,np.abs(PSF_main_lobe));\n",
      "plt.plot(l,fitted_beam);\n",
      "plt.xlim(-0.15,0.15);\n",
      "plt.title('Restoring beam');\n",
      "plt.xlabel('l');\n",
      "plt.ylabel('Amplitude');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we convolve our CLEAN model by the restoring beam, then add back the residual image leftover at the end of the clean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "convolved_image = np.convolve(model_I,restoring_beam,mode='same')\n",
      "\n",
      "restored_image = convolved_image + resid_I"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And lets plot them all!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot amplitudes\n",
      "fig, ax = plt.subplots(1,2,figsize=[16,3])     \n",
      "ax[0].plot(l,np.abs(I));\n",
      "ax[0].set_xlabel('$l$');\n",
      "ax[0].set_ylabel('Amplitude');\n",
      "ax[0].set_title('Original I($l$)');\n",
      "ax[1].plot(l,np.abs(DI));\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('Amplitude');\n",
      "ax[1].set_title('Dirty DI($l$)');\n",
      "\n",
      "fig, ax = plt.subplots(1,2,figsize=[16,3])     \n",
      "ax[0].plot(l,np.abs(model_I));\n",
      "ax[0].set_xlabel('$l$');\n",
      "ax[0].set_ylabel('Amplitude');\n",
      "ax[0].set_title('CLEAN model I($l$)');\n",
      "ax[1].plot(l,np.abs(restored_image));\n",
      "ax[1].set_xlabel('$l$');\n",
      "ax[1].set_ylabel('Amplitude');\n",
      "ax[1].set_title('Final restored I($l$)');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There it is! We performed a manual Hogbom CLEAN.\n",
      "\n",
      "You can re-use this notebook to explore how this CLEAN deconvolution method works with different types of sampling functions or sky models.\n",
      "\n",
      "Try:\n",
      "\n",
      "* A narrower sampling function (that will result in a wider PSF)\n",
      "* Changing the number of sources\n",
      "* Sources that are different distances from to each other\n",
      "\n",
      "Have fun!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Version information###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import IPython\n",
      "import matplotlib\n",
      "\n",
      "print 'Version information'\n",
      "print '==================='\n",
      "print 'OS:          ', os.name, sys.platform\n",
      "print 'Python:      ', sys.version.split()[0]\n",
      "print 'IPython:     ', IPython.__version__\n",
      "print 'Numpy:       ', np.__version__\n",
      "print 'matplotlib:  ', matplotlib.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}